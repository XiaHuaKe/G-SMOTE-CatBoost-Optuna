{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "9384fbb416acb65c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "mdata = pd.read_excel(\"C:/Users/Lenovo/Desktop/landslide.xlsx\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y = mdata['S/N'].values\n",
    "y = y.astype(int)\n",
    "x_data = mdata.drop([\"S/N\"], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(x_data), columns=x_data.columns)\n",
    "x"
   ],
   "id": "b60221a14be5b7da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "s_n_1_data = mdata[mdata['S/N'] == 1].drop([\"S/N\"], axis=1)\n",
    "corr_matrix = s_n_1_data.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,  \n",
    "    annot=True,   \n",
    "    fmt=\".2f\",    \n",
    "    cmap=\"coolwarm\", \n",
    "    vmin=-0.5,      \n",
    "    vmax=1,       \n",
    "    linewidths=0.5,  \n",
    "    linecolor=\"white\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ],
   "id": "b6f7d736d112aa1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr_matrix = x.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,   \n",
    "    annot=True,    \n",
    "    fmt=\".2f\",     \n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-0.5,      \n",
    "    vmax=1,        \n",
    "    linewidths=0.5, \n",
    "    linecolor=\"white\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ],
   "id": "8368e3694e16aedc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels = dbscan.fit_predict(x)\n",
    "\n",
    "cluster_count = len(set(labels) - {-1})\n",
    "print(\"c_count:\", cluster_count)"
   ],
   "id": "d32519b8361887f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "cnum = cluster_count\n",
    "\n",
    "gmm = GaussianMixture(n_components=cnum, random_state=42)\n",
    "gmm.fit(x)\n",
    "\n",
    "clusters = gmm.predict(x)\n",
    "\n",
    "c = gmm.means_  \n",
    "\n",
    "cluster_minority_count = {i: 0 for i in range(cnum)}\n",
    "cluster_total_count = {i: 0 for i in range(cnum)}\n",
    "\n",
    "for i in range(len(x)):\n",
    "    cluster_label = clusters[i]\n",
    "    cluster_total_count[cluster_label] += 1\n",
    "\n",
    "    if y[i] == 1: \n",
    "        cluster_minority_count[cluster_label] += 1\n",
    "\n",
    "cluster_ir = {}\n",
    "for cluster in range(cnum):\n",
    "    majority_count = cluster_total_count[cluster] - cluster_minority_count[cluster]\n",
    "    minority_count = cluster_minority_count[cluster]\n",
    "    if majority_count > 0:\n",
    "        ir = minority_count / majority_count\n",
    "        cluster_ir[cluster] = ir\n",
    "    else:\n",
    "        cluster_ir[cluster] = float('inf')\n",
    "\n",
    "for cluster, ir in cluster_ir.items():\n",
    "    print(f\"C {cluster + 1} IR: {ir:.4f}\")\n"
   ],
   "id": "d542e19f3971f53b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from config import α\n",
    "flag = 0  \n",
    "max = 0  \n",
    "max_ir = 0\n",
    "\n",
    "for cluster, ir in cluster_ir.items():\n",
    "    if ir > α:\n",
    "        flag = 1\n",
    "    if ir > max:\n",
    "        max_ir = cluster\n",
    "        max = ir\n",
    "\n",
    "if flag == 1:\n",
    "    selected_clusters = [cluster for cluster, ir in cluster_ir.items() if ir > α]\n",
    "else:\n",
    "    selected_clusters = [max_ir]\n",
    "\n",
    "unselected_clusters = [cluster for cluster in range(cnum) if cluster not in selected_clusters]\n",
    "\n",
    "print(\"\\n IR > α:\")\n",
    "print(selected_clusters)\n",
    "\n",
    "print(\"\\n IR <= α:\")\n",
    "print(unselected_clusters)\n"
   ],
   "id": "521c84193f86a04b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unselected_minority_samples = []\n",
    "\n",
    "for cluster in unselected_clusters:\n",
    "    \n",
    "    minority_indices = [i for i in range(len(y)) if clusters[i] == cluster and y[i] == 1]\n",
    "    unselected_minority_samples.extend(minority_indices)"
   ],
   "id": "479f936c5d8701f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "counts = np.bincount(y)\n",
    "num = counts[0] - counts[1]\n",
    "\n",
    "\n",
    "majority_samples = [i for i in range(len(y)) if y[i] == 0]\n",
    "X_majority = x.iloc[majority_samples].values\n",
    "y_majority = y[majority_samples]\n",
    "\n",
    "cluster_minority_counts = {}\n",
    "for cluster in selected_clusters:\n",
    "    minority_samples = [i for i in range(len(y)) if clusters[i] == cluster and y[i] == 1]\n",
    "    cluster_minority_counts[cluster] = len(minority_samples)\n",
    "\n",
    "total_minority_samples = sum(cluster_minority_counts.values())\n",
    "\n",
    "new_samples = []\n",
    "for cluster in selected_clusters:\n",
    "    minority_samples = [i for i in range(len(y)) if clusters[i] == cluster and y[i] == 1]\n",
    "    X_minority = x.iloc[minority_samples].values\n",
    "    y_minority = y[minority_samples]\n",
    "\n",
    "    X_combined = np.vstack([X_minority, X_majority])\n",
    "    y_combined = np.concatenate([y_minority, y_majority])\n",
    "    \n",
    "    cluster_ratio = cluster_minority_counts[cluster] / total_minority_samples\n",
    "    num_samples_to_generate = int(num * cluster_ratio)\n",
    "\n",
    "    original_indices = np.arange(len(X_combined))\n",
    "\n",
    "    smote = SMOTE(random_state=42, sampling_strategy={1: num_samples_to_generate + len(minority_samples)})\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_combined, y_combined)\n",
    "\n",
    "    new_indices = np.setdiff1d(np.arange(len(X_resampled)), original_indices)\n",
    "    new_synthetic_samples = X_resampled[new_indices]\n",
    "\n",
    "    new_samples.append(new_synthetic_samples)\n",
    "\n",
    "new_samples = np.vstack(new_samples)\n",
    "\n",
    "for new_sample in new_samples:\n",
    "    print(new_sample)\n",
    "print(len(new_samples))"
   ],
   "id": "474d614c25a22da8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_sample = new_sample.T \n",
    "new_columns = ['dem', 'slope', 'aspect', 'curvature', 'dis_river', 'dis_road', 'dis_fault', 'ndvi', 'ndwi', 'rainfall', 'lithology']\n",
    "new_samples_df = pd.DataFrame(new_samples, columns=new_columns) \n",
    "\n",
    "X_balanced = pd.concat([x, new_samples_df], ignore_index=True)\n",
    "\n",
    "X_balanced"
   ],
   "id": "c1a139403f469428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "new_labels = np.ones(num, dtype=int)  \n",
    "y_balanced = np.concatenate([y, new_labels])\n",
    "\n",
    "print(Counter(y))\n",
    "print(Counter(y_balanced))"
   ],
   "id": "516320ff7429eb45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_smo = X_balanced\n",
    "y_smo = y_balanced"
   ],
   "id": "a823ff7f1f6af64b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "mdata = pd.concat([x, pd.DataFrame(y, columns=['S/N'])], axis=1)\n",
    "x_0 = mdata[mdata['S/N'] == 0].drop(columns=\"S/N\")\n",
    "x_1 = mdata[mdata['S/N'] == 1].drop(columns=\"S/N\")\n",
    "print(len(x_1))\n",
    "\n",
    "mdata1 = pd.concat([x_smo, pd.DataFrame(y_smo, columns=['S/N'])], axis=1)\n",
    "x_0_smo = mdata1[mdata1['S/N'] == 0].drop(columns=\"S/N\")\n",
    "x_1_smo = mdata1[mdata1['S/N'] == 1].drop(columns=\"S/N\")\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)  \n",
    "X_reduced_0_smo = tsne.fit_transform(x_0_smo)\n",
    "X_reduced_1_smo = tsne.fit_transform(x_1_smo)\n",
    "print(len(X_reduced_1_smo))\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_reduced_0_smo[:, 0], X_reduced_0_smo[:, 1], c='red', label='Non-Landslide', alpha=0.6)\n",
    "plt.scatter(X_reduced_1_smo[:len(x_1), 0], X_reduced_1_smo[:len(x_1), 1], c='blue', label='Landslide (Original)', alpha=0.6)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "mdata1 = pd.concat([x_smo, pd.DataFrame(y_smo, columns=['S/N'])], axis=1)\n",
    "x_0_smo = mdata1[mdata1['S/N'] == 0].drop(columns=\"S/N\")\n",
    "x_1_smo = mdata1[mdata1['S/N'] == 1].drop(columns=\"S/N\")\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30) \n",
    "X_reduced_0_smo = tsne.fit_transform(x_0_smo)\n",
    "X_reduced_1_smo = tsne.fit_transform(x_1_smo)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_reduced_0_smo[:, 0], X_reduced_0_smo[:, 1], c='red', label='Non-Landslide', alpha=0.6)\n",
    "plt.scatter(X_reduced_1_smo[:len(x_1), 0], X_reduced_1_smo[:len(x_1), 1], c='blue', label='Landslide (Original)', alpha=0.6)\n",
    "plt.scatter(X_reduced_1_smo[len(x_1):, 0], X_reduced_1_smo[len(x_1):, 1], c='limegreen', marker='^', label='Landslide (Synthetic)', alpha=0.6)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c542e1ed36977172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "mdata = pd.concat([x,pd.DataFrame(y,columns=['S/N'])],axis=1)\n",
    "x_0 = mdata[mdata['S/N'] == 0].drop(columns=\"S/N\")\n",
    "x_1 = mdata[mdata['S/N'] == 1].drop(columns=\"S/N\")\n",
    "x_original = x_1\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced_0 = pca.fit_transform(x_0)\n",
    "X_reduced_1 = pca.fit_transform(x_1)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.scatter(X_reduced_0[:, 0], X_reduced_0[:, 1], c='red', label='Non-Landslide', alpha=0.6)\n",
    "\n",
    "plt.scatter(X_reduced_1[:, 0], X_reduced_1[:, 1], c='blue', label='Landslide', alpha=0.6)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "mdata1 = pd.concat([x_smo, pd.DataFrame(y_smo, columns=['S/N'])], axis=1)\n",
    "\n",
    "x_0 = mdata1[mdata1['S/N'] == 0].drop(columns=\"S/N\")\n",
    "x_1 = mdata1[mdata1['S/N'] == 1].drop(columns=\"S/N\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced_0 = pca.fit_transform(x_0)\n",
    "X_reduced_1 = pca.fit_transform(x_1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_reduced_0[:, 0], X_reduced_0[:, 1], c='red', label='Non-Landslide', alpha=0.6)\n",
    "\n",
    "plt.scatter(X_reduced_1[:len(x_original), 0], X_reduced_1[:len(x_original), 1], c='blue', label='Landslide(Original)', alpha=0.6)\n",
    "plt.scatter(X_reduced_1[len(x_original):, 0], X_reduced_1[len(x_original):, 1],\n",
    "            c='limegreen', marker='^', label='Landslide (Synthetic)', alpha=0.6)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ],
   "id": "a09662bb1ed3891e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verification",
   "id": "4218debad33c0020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=0)\n",
    "kf2 = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mean"
   ],
   "id": "e7c19f78cab40a32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Logistic \n",
    "print(\"---------------Logistic---------------\")\n",
    "lr = LogisticRegression()\n",
    "acc_lr = cross_val_score(lr, x_smo, y_smo, cv=kf, scoring='accuracy')\n",
    "recall = cross_val_score(lr, x_smo, y_smo, cv=kf, scoring='recall')\n",
    "f1 = cross_val_score(lr, x_smo, y_smo, cv=kf, scoring='f1')\n",
    "auc_lr = cross_val_score(lr, x_smo, y_smo, cv=kf, scoring='roc_auc')\n",
    "scores = cross_val_score(lr, x_smo, y_smo, cv=kf)\n",
    "y_pred_prob = cross_val_predict(lr, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "print('Log Loss: %.4f' % log_loss_score)\n",
    "print('Mean Accuracy: %.4f' % mean(acc_lr))\n",
    "print('Mean Recall: %.4f' % mean(recall))\n",
    "print('Mean F1-score: %.4f' % mean(f1))\n",
    "print('Mean AUC: %.4f' % mean(auc_lr))\n",
    "print('Mean scores: %.4f' % mean(scores))\n",
    "\n",
    "#Support Vector Machines(SVM) \n",
    "print(\"---------------SVM---------------\")\n",
    "svm = SVC(random_state=42, probability=True)\n",
    "acc_svm = cross_val_score(svm, x_smo, y_smo, cv=kf, scoring='accuracy')\n",
    "recall = cross_val_score(svm, x_smo, y_smo, cv=kf, scoring='recall')\n",
    "f1 = cross_val_score(svm, x_smo, y_smo, cv=kf, scoring='f1')\n",
    "auc_svm = cross_val_score(svm, x_smo, y_smo, cv=kf, scoring='roc_auc')\n",
    "scores = cross_val_score(svm, x_smo, y_smo, cv=kf)\n",
    "y_pred_prob = cross_val_predict(svm, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "print('Log Loss: %.4f' % log_loss_score)\n",
    "print('Mean Accuracy: %.4f' % mean(acc_svm))\n",
    "print('Mean Recall: %.4f' % mean(recall))\n",
    "print('Mean F1-score: %.4f' % mean(f1))\n",
    "print('Mean AUC: %.4f' % mean(auc_svm))\n",
    "print('Mean scores: %.4f' % mean(scores))\n",
    "\n",
    "#Naive Bayes(NB)\n",
    "print(\"---------------NB---------------\")\n",
    "nb = GaussianNB()\n",
    "acc_nb = cross_val_score(nb, x_smo, y_smo, cv=kf, scoring='accuracy')\n",
    "recall = cross_val_score(nb, x_smo, y_smo, cv=kf, scoring='recall')\n",
    "f1 = cross_val_score(nb, x_smo, y_smo, cv=kf, scoring='f1')\n",
    "auc_nb = cross_val_score(nb, x_smo, y_smo, cv=kf, scoring='roc_auc')\n",
    "scores = cross_val_score(nb, x_smo, y_smo, cv=kf)\n",
    "y_pred_prob = cross_val_predict(nb, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "print('Log Loss: %.4f' % log_loss_score)\n",
    "print('Mean Accuracy: %.4f' % mean(acc_nb))\n",
    "print('Mean Recall: %.4f' % mean(recall))\n",
    "print('Mean F1-score: %.4f' % mean(f1))\n",
    "print('Mean AUC: %.4f' % mean(auc_nb))\n",
    "print('Mean scores: %.4f' % mean(scores))\n",
    "\n",
    "#Decision Tree(DT)\n",
    "print(\"---------------DT---------------\")\n",
    "df = DecisionTreeClassifier(random_state=42)\n",
    "acc_dt = cross_val_score(df, x_smo, y_smo, cv=kf, scoring='accuracy')\n",
    "recall = cross_val_score(df, x_smo, y_smo, cv=kf, scoring='recall')\n",
    "f1 = cross_val_score(df, x_smo, y_smo, cv=kf, scoring='f1')\n",
    "auc_dt = cross_val_score(df, x_smo, y_smo, cv=kf, scoring='roc_auc')\n",
    "scores = cross_val_score(df, x_smo, y_smo, cv=kf)\n",
    "y_pred_prob = cross_val_predict(df, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "print('Log Loss: %.4f' % log_loss_score)\n",
    "print('Mean Accuracy: %.4f' % mean(acc_dt))\n",
    "print('Mean Recall: %.4f' % mean(recall))\n",
    "print('Mean F1-score: %.4f' % mean(f1))\n",
    "print('Mean AUC: %.4f' % mean(auc_dt))\n",
    "print('Mean scores: %.4f' % mean(scores))\n",
    "\n",
    "#Random Forest(RF)\n",
    "print(\"---------------RF---------------\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "acc_rf = cross_val_score(rf, x_smo, y_smo, cv=kf, scoring='accuracy')\n",
    "recall = cross_val_score(rf, x_smo, y_smo, cv=kf, scoring='recall')\n",
    "f1 = cross_val_score(rf, x_smo, y_smo, cv=kf, scoring='f1')\n",
    "auc_rf = cross_val_score(rf, x_smo, y_smo, cv=kf, scoring='roc_auc')\n",
    "scores = cross_val_score(rf, x_smo, y_smo, cv=kf)\n",
    "y_pred_prob = cross_val_predict(rf, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "print('Log Loss: %.4f' % log_loss_score)\n",
    "print('Mean Accuracy: %.4f' % mean(acc_rf))\n",
    "print('Mean Recall: %.4f' % mean(recall))\n",
    "print('Mean F1-score: %.4f' % mean(f1))\n",
    "print('Mean AUC: %.4f' % mean(auc_rf))\n",
    "print('Mean scores: %.4f' % mean(scores))\n"
   ],
   "id": "5b572b4ac60d467e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "from config import xgb_params\n",
    "\n",
    "params = xgb_params\n",
    "model = xgb.XGBClassifier(**params)\n",
    "acc_xgb = cross_val_score(model, x_smo, y_smo, scoring='accuracy', cv=kf)\n",
    "recall = cross_val_score(model, x_smo, y_smo, scoring='recall', cv=kf)\n",
    "f1 = cross_val_score(model, x_smo, y_smo, scoring='f1', cv=kf)\n",
    "auc_xgb = cross_val_score(model, x_smo, y_smo, scoring='roc_auc', cv=kf)\n",
    "\n",
    "print(f\"Mean Accuracy: {acc_xgb.mean():.4f}\")\n",
    "print(f\"Mean Recall: {recall.mean():.4f}\")\n",
    "print(f\"Mean F1-score: {f1.mean():.4f}\")\n",
    "print(f\"Mean AUC: {auc_xgb.mean():.4f}\")"
   ],
   "id": "3e090b5681b836f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from config import cat_params\n",
    "params = cat_params\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "acc_cat = cross_val_score(model, x_smo, y_smo, cv=kf, n_jobs=-1, scoring='accuracy')\n",
    "recall = cross_val_score(model, x_smo, y_smo, scoring='recall', cv=kf, verbose=0, )\n",
    "f1 = cross_val_score(model, x_smo, y_smo, scoring='f1', cv=kf, verbose=0, )\n",
    "auc_cat = cross_val_score(model, x_smo, y_smo, scoring='roc_auc', cv=kf, verbose=0, )\n",
    "\n",
    "print(\"---------------CatBoost---------------\")\n",
    "print(f\"Mean Accuracy: {acc_cat.mean():.4f}\")\n",
    "print(f\"Mean Recall: {recall.mean():.4f}\")\n",
    "print(f\"Mean F1-score: {f1.mean():.4f}\")\n",
    "print(f\"Mean AUC: {auc_cat.mean():.4f}\")"
   ],
   "id": "91f62ebe2c249a99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "from config import lgb_params\n",
    "#LightGBM\n",
    "params = lgb_params\n",
    "\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "acc_lgb = cross_val_score(model, x_smo, y_smo, scoring='accuracy', cv=kf)\n",
    "recall = cross_val_score(model, x_smo, y_smo, scoring='recall', cv=kf)\n",
    "f1 = cross_val_score(model, x_smo, y_smo, scoring='f1', cv=kf)\n",
    "auc_lgb = cross_val_score(model, x_smo, y_smo, scoring='roc_auc', cv=kf)\n",
    "\n",
    "print(\"---------------LightGBM---------------\")\n",
    "print(f\"Mean Accuracy: {acc_lgb.mean():.4f}\")\n",
    "print(f\"Mean Recall: {recall.mean():.4f}\")\n",
    "print(f\"Mean F1-score: {f1.mean():.4f}\")\n",
    "print(f\"Mean AUC: {auc_lgb.mean():.4f}\")"
   ],
   "id": "5aefa4fa7af765d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter optimization",
   "id": "f6d35c8081ffd623"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_smo, y_smo, test_size=0.3, random_state=420)"
   ],
   "id": "d739a1217f49d4f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from config import opt_xgb_param\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = opt_xgb_param\n",
    "\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "   \n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy \n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "study.optimize(objective, n_trials=400)\n",
    "\n",
    "best_params = study.best_params\n",
    "print('best_params:', best_params)\n",
    "print('best_value:', study.best_value)\n",
    "\n",
    "model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "\n",
    "acc_op_xgb = cross_val_score(model, x_smo, y_smo, scoring='accuracy', cv=kf)\n",
    "recall = cross_val_score(model, x_smo, y_smo, scoring='recall', cv=kf)\n",
    "f1 = cross_val_score(model, x_smo, y_smo, scoring='f1', cv=kf)\n",
    "auc_op_xgb = cross_val_score(model, x_smo, y_smo, scoring='roc_auc', cv=kf)\n",
    "y_pred_prob = cross_val_predict(model, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "print(f\"Log Loss: {log_loss_score:.4f}\")\n",
    "\n",
    "print(\"---------------Optuna-XGBoost---------------\")\n",
    "print(f\"Accuracy: {acc_op_xgb.mean():.4f}\")\n",
    "print(f\"Recall: {recall.mean():.4f}\")\n",
    "print(f\"F1-score: {f1.mean():.4f}\")\n",
    "print(f\"AUC: {auc_op_xgb.mean():.4f}\")"
   ],
   "id": "63a04d573e4a6bfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from config import opt_cat_param\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna.visualization as vis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = opt_cat_param\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    " \n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=100, verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy \n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  \n",
    "study.optimize(objective, n_trials=400)  \n",
    "best_params = study.best_params\n",
    "\n",
    "model = CatBoostClassifier(**best_params)\n",
    "\n",
    "acc_op_cat = cross_val_score(model, x_smo, y_smo, scoring='accuracy', cv=kf)\n",
    "recall = cross_val_score(model, x_smo, y_smo, scoring='recall', cv=kf)\n",
    "f1 = cross_val_score(model, x_smo, y_smo, scoring='f1', cv=kf)\n",
    "auc_op_cat = cross_val_score(model, x_smo, y_smo, scoring='roc_auc', cv=kf)\n",
    "y_pred_prob = cross_val_predict(model, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "\n",
    "print('best_params:', best_params)\n",
    "print('best_value:', study.best_value)\n",
    "print(f\"Log Loss: {log_loss_score:.4f}\")\n",
    "\n",
    "print(\"---------------Optuna-CatBoost---------------\")\n",
    "print(f\"Accuracy: {acc_op_cat.mean():.4f}\")\n",
    "print(f\"Recall: {recall.mean():.4f}\")\n",
    "print(f\"F1-score: {f1.mean():.4f}\")\n",
    "print(f\"AUC: {auc_op_cat.mean():.4f}\")\n",
    "    \n",
    "fig_importance = vis.plot_param_importances(study)\n",
    "fig_importance.update_layout(width=800, height=500)\n",
    "fig_importance.show()\n",
    "\n",
    "importance_data = study.trials_dataframe()[['params_' + param for param in study.best_params.keys()]]\n",
    "importance_data.columns = [col.replace('params_', '') for col in importance_data.columns]\n",
    "param_importance = optuna.importance.get_param_importances(study)\n",
    "top_params = list(param_importance.keys())[:3] \n",
    "    \n",
    "fig_history = vis.plot_optimization_history(study)\n",
    "fig_history.update_layout(width=800, height=400)\n",
    "fig_history.show()\n",
    "    \n",
    "fig_slice = vis.plot_slice(study, params=top_params)\n",
    "fig_slice.update_layout(width=1200, height=500)\n",
    "fig_slice.show()"
   ],
   "id": "b74dc12fedfe44f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from config import opt_lgb_param\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "\n",
    "def objective(trial):\n",
    "    param = opt_lgb_param\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dtest = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "    model = lgb.train(param, dtrain, valid_sets=[dtest], num_boost_round=500, \n",
    "                      callbacks=[lgb.early_stopping(100, verbose=False)]) \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]  # 阈值为0.5\n",
    "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "    return accuracy  \n",
    "\n",
    "study = optuna.create_study(direction='maximize')  \n",
    "study.optimize(objective, n_trials=400, show_progress_bar=False) \n",
    "\n",
    "best_params = study.best_params\n",
    "print('best_params:', best_params)\n",
    "print('best_value:', study.best_value)\n",
    "\n",
    "model = lgb.LGBMClassifier(**best_params, verbosity=-1) \n",
    "\n",
    "acc_op_lgb = cross_val_score(model, x_smo, y_smo, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "recall = cross_val_score(model, x_smo, y_smo, scoring='recall', cv=kf, n_jobs=-1)\n",
    "f1 = cross_val_score(model, x_smo, y_smo, scoring='f1', cv=kf, n_jobs=-1)\n",
    "auc_op_lgb = cross_val_score(model, x_smo, y_smo, scoring='roc_auc', cv=kf, n_jobs=-1)\n",
    "y_pred_prob = cross_val_predict(model, x_smo, y_smo, cv=kf2, method='predict_proba')\n",
    "log_loss_score = log_loss(y_smo, y_pred_prob)\n",
    "\n",
    "print(f\"Log Loss: {log_loss_score:.4f}\")\n",
    "print(\"---------------Optuna-LightGBM---------------\")\n",
    "print(f\"Accuracy: {acc_op_lgb.mean():.4f}\")\n",
    "print(f\"Recall: {recall.mean():.4f}\")\n",
    "print(f\"F1-score: {f1.mean():.4f}\")\n",
    "print(f\"AUC: {auc_op_lgb.mean():.4f}\")"
   ],
   "id": "7c579b714b04ae38",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
